{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Resnet\n",
    "There are several variants of different sizes, including Resnet18, Resnet34, Resnet50, Resnet101, and Resnet152, all of which are available from torchvision models. Here we try with Resnet18, Resnet32and Resnet50. For the dataset, Resnet50 gets the best accuracy results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.0\n",
      "Torchvision Version:  0.8.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./food_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 128\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 5\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba206994ce29427b8961e1f83af644d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.3933 Acc: 0.8697\n",
      "val Loss: 0.1411 Acc: 0.9730\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.1363 Acc: 0.9683\n",
      "val Loss: 0.0876 Acc: 0.9790\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9770\n",
      "val Loss: 0.0762 Acc: 0.9780\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.0935 Acc: 0.9760\n",
      "val Loss: 0.0690 Acc: 0.9790\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.0808 Acc: 0.9797\n",
      "val Loss: 0.0628 Acc: 0.9790\n",
      "\n",
      "Training complete in 2m 15s\n",
      "Best val Acc: 0.979000\n"
     ]
    }
   ],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist, label=\"Validation Accuracy\")\n",
    "plt.plot(train_hist, label=\"Training Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}