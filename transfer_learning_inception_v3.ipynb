{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Inception V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.0\n",
      "Torchvision Version:  0.8.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./food_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"inception\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 128\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 5\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.8423 Acc: 0.7033\n",
      "val Loss: 0.4077 Acc: 0.9610\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4830 Acc: 0.9217\n",
      "val Loss: 0.2702 Acc: 0.9680\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3531 Acc: 0.9427\n",
      "val Loss: 0.2165 Acc: 0.9710\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3008 Acc: 0.9507\n",
      "val Loss: 0.1846 Acc: 0.9750\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2736 Acc: 0.9550\n",
      "val Loss: 0.1614 Acc: 0.9760\n",
      "\n",
      "Training complete in 3m 37s\n",
      "Best val Acc: 0.976000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist,train_hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, \n",
    "                             num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist, label=\"Validation Accuracy\")\n",
    "plt.plot(train_hist, label=\"Training Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
